
@misc{noauthor_c2comdocoopsla92html_nodate,
	title = {c2.com/doc/oopsla92.html},
	url = {https://c2.com/doc/oopsla92.html},
	urldate = {2026-02-02},
}

@misc{noauthor_iso_nodate,
	title = {{ISO} 25010},
	url = {https://iso25000.com/index.php/en/iso-25000-standards/iso-25010},
	urldate = {2026-02-02},
}

@inproceedings{oman_metrics_1992,
	title = {Metrics for assessing a software system's maintainability},
	url = {https://ieeexplore.ieee.org/document/242525},
	doi = {10.1109/ICSM.1992.242525},
	abstract = {It is noted that the factors of software that determine or influence maintainability can be organized into a hierarchical structure of measurable attributes. For each of these attributes the authors show a metric definition consistent with the published definitions of the software characteristic being measured. The result is a tree structure of maintainability metrics which can be used for purposes of evaluating the relative maintainability of the software system. The authors define metrics for measuring the maintainability of a target software system and discuss how those metrics can be combined into a single index of maintainability.{\textbackslash}textless{\textbackslash}textgreater},
	urldate = {2026-02-02},
	booktitle = {Proceedings {Conference} on {Software} {Maintenance} 1992},
	author = {Oman, P. and Hagemeister, J.},
	month = nov,
	year = {1992},
	keywords = {Documentation, Software engineering, Software systems, Environmental management, Lifting equipment, Software maintenance, Software measurement, Software testing, Taxonomy, Tree data structures},
	pages = {337--344},
}

@inproceedings{xiao_identifying_2016,
	address = {Austin Texas},
	title = {Identifying and quantifying architectural debt},
	isbn = {978-1-4503-3900-1},
	url = {https://dl.acm.org/doi/10.1145/2884781.2884822},
	doi = {10.1145/2884781.2884822},
	abstract = {Our prior work showed that the majority of error-prone source ﬁles in a software system are architecturally connected. Flawed architectural relations propagate defects among these ﬁles and accumulate high maintenance costs over time, just like debts accumulate interest. We model groups of architecturally connected ﬁles that accumulate high maintenance costs as architectural debts. To quantify such debts, we formally deﬁne architectural debt, and show how to automatically identify debts, quantify their maintenance costs, and model these costs over time. We describe a novel history coupling probability matrix for this purpose, and identify architecture debts using 4 patterns of architectural ﬂaws shown to correlate with reduced software quality. We evaluate our approach on 7 large-scale open source projects, and show that a signiﬁcant portion of total project maintenance eﬀort is consumed by paying interest on architectural debts. The top 5 architectural debts, covering a small portion (8\% to 25\%) of each project’s error-prone ﬁles, capture a signiﬁcant portion (20\% to 61\%) of each project’s maintenance eﬀort. Finally, we show that our approach reveals how architectural issues evolve into debts over time.},
	language = {en},
	urldate = {2026-02-01},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Xiao, Lu and Cai, Yuanfang and Kazman, Rick and Mo, Ran and Feng, Qiong},
	month = may,
	year = {2016},
	pages = {488--498},
}

@article{hassan_characterising_2025,
	title = {Characterising reproducibility debt in scientific software: {A} systematic literature review},
	volume = {222},
	issn = {0164-1212},
	shorttitle = {Characterising reproducibility debt in scientific software},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121224003716},
	doi = {10.1016/j.jss.2024.112327},
	abstract = {Context: In scientific software, the inability to reproduce results is often due to technical issues and challenges in recreating the full computational workflow from the original analysis. We conceptualise this problem as Reproducibility Debt (RpD). Much research has been performed to propose solutions to tackle these issues across various computational science disciplines. It is essential to identify and accumulate existing knowledge on reproducibility issues and state-of-the-art solutions so as to provide researchers and practitioners with information that enables further research activities and RpD management in practice. Objective: In the context of scientific software, we aim to characterise RpD by providing a taxonomy of issues contributing towards its emergence and identification (causes, effects) and the common solutions discussed in the existing literature. Method: We conducted a systematic literature review, considering 2198 studies until January 2024, including 214 primary studies. Results: We propose the first taxonomy of RpD items consisting of 37 causes attributed towards its emergence, 63 corresponding effects under seven main categories, and 29 prevention strategies. We also identify 39 specialised tools/frameworks supporting reproducibility. Conclusion: The main contributions of this work are (1) a formal definition of RpD; (2) a taxonomy of issues contributing towards RpD; (3) a list of causes and effects having implications for software professionals to identify and measure RpD in their projects; (4) a list of strategies and tools to prevent or remove RpD; (5) the identification of gaps in existing research to guide future studies.},
	urldate = {2026-02-02},
	journal = {Journal of Systems and Software},
	author = {Hassan, Zara and Treude, Christoph and Norrish, Michael and Williams, Graham and Potanin, Alex},
	month = apr,
	year = {2025},
	keywords = {Computational reproducibility, Reproducibility debt, Scientific software, Systematic literature review, Technical debt},
	pages = {112327},
}

@article{ramac_prevalence_2022,
	title = {Prevalence, common causes and effects of technical debt: {Results} from a family of surveys with the {IT} industry},
	volume = {184},
	issn = {0164-1212},
	shorttitle = {Prevalence, common causes and effects of technical debt},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221002119},
	doi = {10.1016/j.jss.2021.111114},
	abstract = {Context: The technical debt (TD) metaphor describes actions made during various stages of software development that lead to a more costly future regarding system maintenance and evolution. According to recent studies, on average 25\% of development effort is spent, i.e. wasted, on TD caused issues in software development organizations. However, further research is needed to investigate the relations between various software development activities and TD. Objective: The objective of this study is twofold. First, to get empirical insight on the understanding and the use of the TD concept in the IT industry. Second, to contribute towards precise conceptualization of the TD concept through analysis of causes and effects. Method: In order to address the research objective a family of surveys was designed as a part of an international initiative that congregates researchers from 12 countries—InsighTD. At country level, national teams ran survey replications with industry practitioners from the respective countries. Results: In total 653 valid responses were collected from 6 countries. Regarding the prevalence of the TD concept 22\% of practitioners have only theoretical knowledge about it, and 47\% have some practical experiences with TD identification or management. Further analysis indicated that senior practitioners who work in larger organizations, larger teams, and on larger systems are more likely to be experienced with TD management. Time pressure or deadlinewas the single most cited cause of TD. Regarding the effects of TD: delivery delay, low maintainability, and rework were the most cited. Conclusion: InsighTD is the first family of surveys on technical debt in software engineering. It provided a methodological framework that allowed multiple replication teams to conduct research activities and to contribute to a single dataset. Future work will focus on more specific aspects of TD management.},
	urldate = {2026-02-02},
	journal = {Journal of Systems and Software},
	author = {Ramač, Robert and Mandić, Vladimir and Taušan, Nebojša and Rios, Nicolli and Freire, Sávio and Pérez, Boris and Castellanos, Camilo and Correal, Darío and Pacheco, Alexia and Lopez, Gustavo and Izurieta, Clemente and Seaman, Carolyn and Spinola, Rodrigo},
	month = feb,
	year = {2022},
	keywords = {Technical debt, Causes of technical debt, Effects of technical debt, InsighTD, Survey},
	pages = {111114},
}

@article{coleman_using_1994,
	title = {Using {Metrics} to {Evaluate} {Software} {System} {Maintainability}},
	volume = {27},
	doi = {10.1109/2.303623},
	abstract = {Software metrics have been much criticized in the last few years, sometimes justly but more often unjustly, because critics misunderstand the intent behind the technology. Software complexity metrics, for example, rarely measure the “inherent complexity” embedded in software systems, but they do a very good job of comparing the relative complexity of one portion of a system with another. In essence, they are good modeling tools. Whether they are also good measuring tools depends on how consistently and appropriately they are applied},
	journal = {Computer},
	author = {Coleman, Don and Ash, Dan and Lowther, Bruce and Oman, Paul},
	month = sep,
	year = {1994},
	pages = {44--49},
}

@article{trisovic_large-scale_2022,
	title = {A large-scale study on research code quality and execution},
	volume = {9},
	issn = {2052-4463},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC8861064/},
	doi = {10.1038/s41597-022-01143-6},
	abstract = {This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74\% of R files failed to complete without error in the initial execution, while 56\% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.},
	urldate = {2026-01-26},
	journal = {Scientific Data},
	author = {Trisovic, Ana and Lau, Matthew K. and Pasquier, Thomas and Crosas, Mercè},
	month = feb,
	year = {2022},
	pages = {60},
}

@inproceedings{anthony_were_2024,
	title = {We're {Drifting} {Apart}: {Architectural} {Drift} from the {Developers}' {Perspective}},
	issn = {2835-7043},
	shorttitle = {We're {Drifting} {Apart}},
	url = {https://ieeexplore.ieee.org/abstract/document/10592790},
	doi = {10.1109/ICSA59870.2024.00018},
	abstract = {Despite the recognized importance of software architecture, it is common that the implementation diverges from the intended architecture over time. This phenomenon is referred to as architectural drift. In the past decades, mainly technical solutions and tools have been developed to detect and address architectural inconsistencies and drift. There is still a lack of evidence from the perspective of developers and a lack of best practices to manage drift. This mixed-methods study relies on interviews with 11 developers and a survey answered by 63 developers from different companies and domains. We analyzed the data by dividing developers into senior and junior to see the different perspectives based on work experience. We found that juniors tend to rely more on documentation, while seniors have a more experience-related approach. We identified practices that developers use to mitigate drift, including defining clear responsibilities, setting best practices, and maintaining reliable documentation. Finally, we designed and evaluated guidelines to help developers to face architectural drift.},
	urldate = {2026-01-27},
	booktitle = {2024 {IEEE} 21st {International} {Conference} on {Software} {Architecture} ({ICSA})},
	author = {Anthony, Emilie and Berntsson, Astrid and Santilli, Tiziano and Wohlrab, Rebekka},
	month = jun,
	year = {2024},
	keywords = {Architectural drift, Companies, Computer architecture, Documentation, Face recognition, interviews, Software architecture, Software reliability, survey, Surveys},
	pages = {101--111},
	annote = {ISSN: 2835-7043},
}

@inproceedings{weyuker_empirical_2011,
	title = {Empirical {Software} {Engineering} {Research} - {The} {Good}, {The} {Bad}, {The} {Ugly}},
	issn = {1949-3789},
	url = {https://ieeexplore.ieee.org/abstract/document/6092548},
	doi = {10.1109/ESEM.2011.66},
	abstract = {The Software Engineering Research community has slowly recognized that empirical studies are an important way of validating ideas and increasingly our community has stopped accepting the sufficiency of arguing that a smart person has come up with the idea and therefore it must be good. This has led to a flood of Software Engineering papers that contain at least some form of empirical study. However, not all empirical studies are created equal, and many may not even provide any useful information or value. We survey the gradual shift from essentially no empirical studies, to a small number of ones of questionable value, and look at what we need to do to insure that our empirical studies really contribute to the state of knowledge in the field. Thus we have the good, the bad, and the ugly. What are we as a community doing correctly? What are we doing less well than we should be because we either don't have the necessary artifacts or because the time and resources required to do "the good" is perceived to be too great? And where are we missing the boat entirely in terms of not addressing critical questions and often not even recognizing that these questions are central even if we don't know the answers. We look to see whether we can find some commonality in the projects that have really made the transition from research to widespread practice to see whether we can identify some common themes.},
	urldate = {2026-01-27},
	booktitle = {2011 {International} {Symposium} on {Empirical} {Software} {Engineering} and {Measurement}},
	author = {Weyuker, Elaine J.},
	month = sep,
	year = {2011},
	keywords = {adoption of research, Communities, Computers, empirical studies, Production, software engineering, Software engineering, Software systems, Testing, validating experiments},
	pages = {1--9},
	annote = {ISSN: 1949-3789},
}

@article{jolak_empirical_2025,
	title = {An empirical investigation of the impact of architectural smells on software maintainability},
	volume = {225},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:miun:diva-53992},
	abstract = {In recent years, interest in the potential influence of architectural smells on software maintainability has grown. Yet, empirical evidence directly linking maintainability quality attributes — suc ...},
	language = {eng},
	urldate = {2026-01-27},
	journal = {Journal of Systems and Software},
	publisher = {Elsevier BV},
	author = {Jolak, Rodi and Karlsson, Simon and Dobslaw, Felix},
	year = {2025},
}

@misc{noauthor_architectural_nodate,
	title = {Architectural technical debt identification {\textbackslash}textbackslashtextbar {Proceedings} of the 2018 {International} {Conference} on {Technical} {Debt}},
	url = {https://dl-acm-org.glucksman.idm.oclc.org/doi/10.1145/3194164.3194176},
	urldate = {2026-01-27},
}

@article{parnas_criteria_1972,
	title = {On the criteria to be used in decomposing systems into modules},
	volume = {15},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/361598.361623},
	doi = {10.1145/361598.361623},
	abstract = {This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a “modularization” is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched.},
	number = {12},
	urldate = {2026-02-04},
	journal = {Commun. ACM},
	author = {Parnas, D. L.},
	month = dec,
	year = {1972},
	pages = {1053--1058},
}

@article{marwick_computational_2017,
	title = {Computational {Reproducibility} in {Archaeological} {Research}: {Basic} {Principles} and a {Case} {Study} of {Their} {Implementation}},
	volume = {24},
	issn = {1573-7764},
	shorttitle = {Computational {Reproducibility} in {Archaeological} {Research}},
	url = {https://doi.org/10.1007/s10816-015-9272-9},
	doi = {10.1007/s10816-015-9272-9},
	abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other’s work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
	language = {en},
	number = {2},
	urldate = {2026-02-07},
	journal = {Journal of Archaeological Method and Theory},
	author = {Marwick, Ben},
	month = jun,
	year = {2017},
	keywords = {Software engineering, Australian archaeology, Computer programming, Open science, Reproducible research},
	pages = {424--450},
}

@article{eglen_towards_2017,
	title = {Towards standard practices for sharing computer code and programs in neuroscience},
	volume = {20},
	issn = {1097-6256},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC6386137/},
	doi = {10.1038/nn.4550},
	abstract = {Computational techniques are central in many areas of neuroscience, and are relatively easy to share. This paper describes why computer programs underlying scientific publications should be shared, and lists simple steps for sharing. Together with ongoing efforts in data sharing, this should aid reproducibility of research.},
	number = {6},
	urldate = {2026-02-07},
	journal = {Nature neuroscience},
	author = {Eglen, Stephen J. and Marwick, Ben and Halchenko, Yaroslav O. and Hanke, Michael and Sufi, Shoaib and Gleeson, Padraig and Silver, R. Angus and Davison, Andrew P. and Lanyon, Linda and Abrams, Mathew and Wachtler, Thomas and Willshaw, David J. and Pouzat, Christophe and Poline, Jean-Baptiste},
	month = may,
	year = {2017},
	pages = {770--773},
}

@misc{jimenez_four_2017,
	title = {Four simple recommendations to encourage best practices in research software},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	url = {https://f1000research.com/articles/6-876},
	doi = {10.12688/f1000research.11407.1},
	abstract = {Scientific research relies on computer software, yet software is not always developed following practices that ensure its quality and sustainability. This manuscript does not aim to propose new software development best practices, but rather to provide simple recommendations that encourage the adoption of existing best practices. Software development best practices promote better quality software, and better quality software improves the reproducibility and reusability of research. These recommendations are designed around Open Source values, and provide practical suggestions that contribute to making research software and its source code more discoverable, reusable and transparent. This manuscript is aimed at developers, but also at organisations, projects, journals and funders that can increase the quality and sustainability of research software by encouraging the adoption of these recommendations.},
	language = {en},
	urldate = {2026-02-07},
	publisher = {F1000Research},
	author = {Jiménez, Rafael C. and Kuzak, Mateusz and Alhamdoosh, Monther and Barker, Michelle and Batut, Bérénice and Borg, Mikael and Capella-Gutierrez, Salvador and Hong, Neil Chue and Cook, Martin and Corpas, Manuel and Flannery, Madison and Garcia, Leyla and Gelpí, Josep Ll and Gladman, Simon and Goble, Carole and Ferreiro, Montserrat González and Gonzalez-Beltran, Alejandra and Griffin, Philippa C. and Grüning, Björn and Hagberg, Jonas and Holub, Petr and Hooft, Rob and Ison, Jon and Katz, Daniel S. and Leskošek, Brane and Gómez, Federico López and Oliveira, Luis J. and Mellor, David and Mosbergen, Rowland and Mulder, Nicola and Perez-Riverol, Yasset and Pergl, Robert and Pichler, Horst and Pope, Bernard and Sanz, Ferran and Schneider, Maria V. and Stodden, Victoria and Suchecki, Radosław and Vařeková, Radka Svobodová and Talvik, Harry-Anton and Todorov, Ilian and Treloar, Andrew and Tyagi, Sonika and Gompel, Maarten van and Vaughan, Daniel and Via, Allegra and Wang, Xiaochuan and Watson-Haigh, Nathan S. and Crouch, Steve},
	month = jun,
	year = {2017},
	keywords = {sustainability, best practices, code, FAIR, guidelines, Open Science, Open Source, quality, recommendations, software},
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	language = {en},
	number = {10},
	urldate = {2026-02-07},
	journal = {PLOS Computational Biology},
	publisher = {Public Library of Science},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	keywords = {Archives, Computer and information sciences, Computer applications, Genome analysis, Habits, Replication studies, Reproducibility, Source code},
	pages = {e1003285},
}

@article{piccolo_tools_2016,
	title = {Tools and techniques for computational reproducibility},
	volume = {5},
	issn = {2047-217X},
	url = {https://doi.org/10.1186/s13742-016-0135-4},
	doi = {10.1186/s13742-016-0135-4},
	abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed—and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.},
	number = {1},
	urldate = {2026-02-07},
	journal = {GigaScience},
	author = {Piccolo, Stephen R and Frampton, Michael B},
	month = dec,
	year = {2016},
	pages = {s13742--016--0135--4},
}

@article{wilson_best_2014,
	title = {Best {Practices} for {Scientific} {Computing}},
	volume = {12},
	issn = {1544-9173},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC3886731/},
	doi = {10.1371/journal.pbio.1001745},
	abstract = {We describe a set of best practices for scientific software development, based on research and experience, that will improve scientists' productivity and the reliability of their software.},
	number = {1},
	urldate = {2026-02-07},
	journal = {PLoS Biology},
	author = {Wilson, Greg and Aruliah, D. A. and Brown, C. Titus and Chue Hong, Neil P. and Davis, Matt and Guy, Richard T. and Haddock, Steven H. D. and Huff, Kathryn D. and Mitchell, Ian M. and Plumbley, Mark D. and Waugh, Ben and White, Ethan P. and Wilson, Paul},
	month = jan,
	year = {2014},
	pages = {e1001745},
}

@article{wilson_software_2006,
	title = {Software {Carpentry}: {Getting} {Scientists} to {Write} {Better} {Code} by {Making} {Them} {More} {Productive}},
	volume = {8},
	issn = {1558-366X},
	shorttitle = {Software {Carpentry}},
	url = {https://ieeexplore.ieee.org/document/1717319},
	doi = {10.1109/MCSE.2006.122},
	abstract = {For the past years, my colleagues and I have developed a one-semester course that teaches scientists and engineers the "common core" of modern software development. Our experience shows that an investment of 150 hours-25 of lectures and the rest of practical work-can improve productivity by roughly 20 percent. That's one day a week, one less semester in a master's degree, or one less year for a typical PhD. The course is called software carpentry, rather than software engineering, to emphasize the fact that it focuses on small-scale and immediately practical issues. All of the material is freely available under an open-source license at www.swc.scipy.org and can be used both for self-study and in the classroom. This article describes what the course contains, and why},
	number = {6},
	urldate = {2026-02-07},
	journal = {Computing in Science \& Engineering},
	author = {Wilson, G.},
	month = nov,
	year = {2006},
	keywords = {software engineering, computation in undergraduate education, Computer science, continuing education, Debugging, Ethics, Java, Open source software, Physics, physics education, Portable computers, Programming profession, Teamwork, World Wide Web},
	pages = {66--69},
}

@article{howison_sustainability_nodate,
	title = {The sustainability of scientific software:},
	abstract = {The sustainability of scientific software is a key challenge for science policy. We approach this question by drawing on empirical studies of scientists using software and describe how components are arranged with complements and dependencies into value-­providing assemblies, periodically revisited by their scientist users. Over time, software declines in scientific usefulness, driven by four factors: a moving scientific frontier and technological change, production friction, use friction and the software ecosystem context. In particular we highlight the impact of the complexity of ecosystem context, in terms of the diversity of use-­‐contexts in which a component is used. We identify three broad strategies to address the need for work to sustain the usefulness of scientific software: suppress the drivers, reduce the amount of work needed, or attract sufficient resources able to undertake the work needed to sustain scientific usefulness. We examine three attraction systems: commercial markets, community-­‐based peer-­‐production and grant-­‐making. We describe how these systems bring resources to projects, and particularly highlight how both commercial markets and peer production address the challenges of ecosystem complexity while scientific grant-­‐making does not. We conclude by making science policy recommendations to address the challenges of sustainability, by enhancing the grant-­making system and by facilitating transitions to other resource attraction systems.},
	language = {en},
	author = {Howison, James and Herbsleb, James D},
}

@inproceedings{johnson_lint_1978,
	title = {Lint, a {C} {Program} {Checker}},
	url = {https://www.semanticscholar.org/paper/Lint%2C-a-C-Program-Checker-Johnson-Hill/74617cffa3c6438d04aa99bef1cca415de47d0d3},
	abstract = {Lint is a command which examines C source programs, detecting a number of bugs and obscurities. It enforces the type rules of C more strictly than the C com- pilers. It may also be used to enforce a number of portability restrictions involved in moving programs between different machines and/or operating systems. Another option detects a number of wasteful, or error prone, constructions which nevertheless are, strictly speaking, legal. Lint accepts multiple input files and library specifications, and checks them for consistency. The separation of function between lint and the C compilers has both historical and practical rationale. The compilers turn C programs into executable files rapidly and efficiently. This is possible in part because the compilers do not do sophisticated type checking, especially between separately compiled programs. Lint takes a more global, leisurely view of the program, looking much more carefully at the compatibili- ties. This document discusses the use of lint , gives an overview of the implementa- tion, and gives some hints on the writing of machine independent C code.},
	urldate = {2026-02-08},
	author = {Johnson, S. and Hill, Murray},
	year = {1978},
	annote = {[TLDR] This document discusses the use of lint, gives an overview of the implementa- tion, and gives some hints on the writing of machine independent C code.},
}

@misc{noauthor_ast-enhanced_nodate,
	title = {{AST}-{Enhanced} or {AST}-{Overloaded}? {The} {Surprising} {Impact} of {Hybrid} {Graph} {Representations} on {Code} {Clone} {Detection}},
	url = {https://arxiv.org/html/2506.14470v1},
	urldate = {2026-02-10},
	file = {AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection:C\:\\Users\\AOLiathain\\Zotero\\storage\\D5TBFY4D\\2506.html:text/html},
}

@book{fowler_refactoring_2019,
	address = {Boston},
	edition = {Second edition},
	series = {Addison-{Wesley} signature series},
	title = {Refactoring: improving the design of existing code},
	isbn = {978-0-13-475759-9},
	shorttitle = {Refactoring},
	publisher = {Addison-Wesley},
	author = {Fowler, Martin},
	year = {2019},
	keywords = {Object-oriented programming (Computer science), Software reengineering},
}

@incollection{fowler_chapter_2019,
	address = {Boston},
	edition = {Second edition},
	series = {Addison-{Wesley} signature series},
	title = {Chapter 1: {Refactoring}: {A} {First} {Example}},
	isbn = {978-0-13-475759-9},
	booktitle = {Refactoring: improving the design of existing code},
	publisher = {Addison-Wesley},
	collaborator = {Fowler, Martin},
	year = {2019},
	keywords = {Object-oriented programming (Computer science), Software reengineering},
	pages = {5--55},
}

@misc{noauthor_catalog_nodate,
	title = {Catalog of {Refactorings}},
	url = {https://refactoring.com/catalog/},
	urldate = {2026-02-10},
	file = {Catalog of Refactorings:C\:\\Users\\AOLiathain\\Zotero\\storage\\M5ITNFYJ\\catalog.html:text/html},
}
